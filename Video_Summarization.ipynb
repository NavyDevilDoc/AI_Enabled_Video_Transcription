{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import io\n",
    "from pydub import AudioSegment\n",
    "from pytube import YouTube\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit_with_error(message, error):\n",
    "    print(f\"{message}: {error}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "def cleanup_files(folder_path):\n",
    "    files_to_delete = ['audio_downloaded_short.mp4', 'audio_downloaded_long.mp4', 'transcript.txt', 'audio_downloaded_long_chunks']\n",
    "\n",
    "    for filename in files_to_delete:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            # Check if the file exists\n",
    "            if os.path.exists(file_path):\n",
    "                # Close the file if it's open\n",
    "                open_files = [f for f in globals() if isinstance(globals()[f], io.IOBase)]\n",
    "                if file_path in open_files:\n",
    "                    globals()[file_path].close()\n",
    "                # Delete the file\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted file: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while deleting file {file_path}: {e}\")\n",
    "\n",
    "\n",
    "def download_audio(video_url, audio_file_path):\n",
    "    print('Prepping the audio file download...')\n",
    "    youtube = YouTube(video_url)\n",
    "    audio = youtube.streams.filter(only_audio=True).first()\n",
    "    print('Downloading the audio file...')\n",
    "    audio.download(filename=audio_file_path)\n",
    "    return audio\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_path, transcription_path):\n",
    "    try:\n",
    "        audio_file = open(os.path.join(base_path, file_extension), 'rb')\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "          model=\"whisper-1\", \n",
    "          file=audio_file)\n",
    "        print('Writing transcript file...')\n",
    "        with open(transcription_path, \"w\") as file:\n",
    "            file.write(transcription.text)\n",
    "    except Exception as e:\n",
    "        exit_with_error(\"Error transcribing audio\", e)\n",
    "\n",
    "\n",
    "def split_audio(audio_path, chunk_size_ms):\n",
    "    # Load the audio file using PyDub\n",
    "    print('Grabbing audio from the video...')\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "\n",
    "    # Calculate number of chunks\n",
    "    num_chunks = len(audio) // chunk_size_ms + (1 if len(audio) % chunk_size_ms > 0 else 0)\n",
    "    chunk_paths = []\n",
    "\n",
    "    # Create directory to store audio chunks if it doesn't exist\n",
    "    base_path = os.path.splitext(audio_path)[0] + \"_chunks\"\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "    # Split the audio and export each chunk\n",
    "    print('Splitting the audio into discrete files...')\n",
    "    for i in range(num_chunks):\n",
    "        start_ms = i * chunk_size_ms\n",
    "        end_ms = start_ms + chunk_size_ms\n",
    "        chunk = audio[start_ms:end_ms]\n",
    "        chunk_file_path = os.path.join(base_path, f\"chunk_{i + 1}.mp3\")\n",
    "        chunk.export(chunk_file_path, format=\"mp3\")\n",
    "        chunk_paths.append(chunk_file_path)\n",
    "\n",
    "    return chunk_paths\n",
    "\n",
    "\n",
    "def transcribe_and_append_audio(audio_path, output_file, chunk_size_ms):\n",
    "    try:\n",
    "        # Split the audio into chunks\n",
    "        chunk_paths = split_audio(audio_path, chunk_size_ms)\n",
    "\n",
    "        # Iterate through each audio chunk and transcribe it\n",
    "        for chunk_path in chunk_paths:\n",
    "            print(f'Transcribing audio chunk {chunk_path}...')\n",
    "            with open(chunk_path, 'rb') as file:\n",
    "                transcription = client.audio.transcriptions.create(model=\"whisper-1\", file=file)\n",
    "                # Append the transcribed text to the output file\n",
    "                with open(output_file, \"a\") as out_file:\n",
    "                    out_file.write(transcription.text.strip() + \"\\n\")\n",
    "    except Exception as e:\n",
    "        exit_with_error(\"Error transcribing audio chunks\", e)\n",
    "\t\t\n",
    "\n",
    "def format_text(input_text, n=100):\n",
    "    print('Formatting output text...')\n",
    "    # First pass: Add a newline after each colon\n",
    "    input_text = input_text.replace(':', ':\\n')\n",
    "    \n",
    "    # Second pass: Add a newline every n characters, taking the new lines into account\n",
    "    formatted_text = ''\n",
    "    current_length = 0  # Track the current length of the line\n",
    "    \n",
    "    for word in input_text.split(' '):  # Split the text into words\n",
    "        word_length = len(word)\n",
    "        if current_length + word_length > n:\n",
    "            # If adding the next word exceeds the limit, start a new line\n",
    "            formatted_text += '\\n' + word\n",
    "            current_length = word_length\n",
    "        else:\n",
    "            # Otherwise, add the word to the current line\n",
    "            if formatted_text:  # Add a space before the word if it's not the start of the text\n",
    "                formatted_text += ' '\n",
    "                current_length += 1  # Account for the added space\n",
    "            formatted_text += word\n",
    "            current_length += word_length\n",
    "        \n",
    "        # Account for newlines within the word itself (e.g., after a colon)\n",
    "        newline_count = word.count('\\n')\n",
    "        if newline_count > 0:\n",
    "            # Reset the current length for new lines\n",
    "            current_length = word_length - word.rfind('\\n') - 1\n",
    "    \n",
    "    return formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables and video link\n",
    "load_dotenv("put_your_path_here")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#YOUTUBE_VIDEO_SHORT = \"https://www.youtube.com/watch?v=HQnPp9b7IOk&t=2s\"\n",
    "YOUTUBE_VIDEO_SHORT = \"https://www.youtube.com/watch?v=QVKj3LADCnA&list=PLPQAixVXrNTUw464KbIvuvH-86jqHGBlz\"\n",
    "YOUTUBE_VIDEO_LONG = \"https://www.youtube.com/watch?v=cdiD-9MMpb0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting the model...\n"
     ]
    }
   ],
   "source": [
    "# Select the model and load the embeddings\n",
    "print('Selecting the model...')\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "#MODEL = \"llama2\"\n",
    "if MODEL.startswith(\"gpt\"):\n",
    "    model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=MODEL)\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "else:\n",
    "    model = Ollama(model=MODEL)\n",
    "    embeddings = OllamaEmbeddings(model=MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning the folder...\n",
     ]
    }
   ],
   "source": [
    "# Define the paths\n",
    "base_path = put_your_path_here\n",
    "\n",
    "print('Cleaning the folder...')\n",
    "cleanup_files(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the desired audio and put it into a local file\n",
    "client = OpenAI()\n",
    "\n",
    "video_length = 'long'\n",
    "\n",
    "if video_length == 'short':\n",
    "    video_url = YOUTUBE_VIDEO_SHORT\n",
    "    file_extension = 'audio_downloaded_short.mp4'\n",
    "elif video_length == 'long':\n",
    "    video_url = YOUTUBE_VIDEO_LONG\n",
    "    file_extension = 'audio_downloaded_long.mp4'\n",
    "\n",
    "transcription_path = os.path.join(base_path, \"transcript.txt\")\n",
    "audio_path = os.path.join(base_path, file_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepping the audio file download...\n",
      "Downloading the audio file...\n",
      "Total size of the audio file: 76.39 MB\n"
     ]
    }
   ],
   "source": [
    "download_audio(video_url, audio_path)\n",
    "total_size = (os.path.getsize(audio_path))/1000000\n",
    "print(f\"Total size of the audio file: {total_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file greater than 25 MB. Splitting and transcribing audio.\n",
      "Grabbing audio from the video...\n",
      "Splitting the audio into discrete files...\n",
      "Transcribing audio chunk C:\\Users\\jspri\\Desktop\\RAG_Model\\audio_downloaded_long_chunks\\chunk_1.mp3...\n",
      "Transcribing audio chunk C:\\Users\\jspri\\Desktop\\RAG_Model\\audio_downloaded_long_chunks\\chunk_2.mp3...\n",
      "Transcribing audio chunk C:\\Users\\jspri\\Desktop\\RAG_Model\\audio_downloaded_long_chunks\\chunk_3.mp3...\n",
      "Transcribing audio chunk C:\\Users\\jspri\\Desktop\\RAG_Model\\audio_downloaded_long_chunks\\chunk_4.mp3...\n",
      "Transcribing audio chunk C:\\Users\\jspri\\Desktop\\RAG_Model\\audio_downloaded_long_chunks\\chunk_5.mp3...\n",
      "Transcribing audio chunk C:\\Users\\jspri\\Desktop\\RAG_Model\\audio_downloaded_long_chunks\\chunk_6.mp3...\n"
     ]
    }
   ],
   "source": [
    "input_file = audio_path\n",
    "chunk_size_ms = 10 * 60 * 1000  # 10 minutes in milliseconds\n",
    "if total_size < 25:\n",
    "    print('Downloaded file less than 25 MB. Transcribing audio.')\n",
    "    transcribe_audio(audio_path, transcription_path)\n",
    "else: \n",
    "    print('Downloaded file greater than 25 MB. Splitting and transcribing audio.')\n",
    "    transcribe_and_append_audio(audio_path, transcription_path, chunk_size_ms)\n",
    "print('Audio transcription complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text...\n",
      "Splitting text...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print('Loading text...')\n",
    "    loader = TextLoader(transcription_path)\n",
    "    text_documents = loader.load()\n",
    "    if not text_documents:\n",
    "        raise ValueError(\"No documents loaded from transcription.\")\n",
    "\n",
    "    print('Splitting text...')\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "    documents = text_splitter.split_documents(text_documents)\n",
    "    if not documents:\n",
    "        raise ValueError(\"Document splitting failed.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during text processing: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up RAG model\n",
    "parser = StrOutputParser()\n",
    "template = \"\"\"\n",
    "Based on the context provided, answer the question \n",
    "with a detailed explanation. If the question is unclear or \n",
    "lacks sufficient context to provide an informed answer, \n",
    "respond with \"I don't know\" or ask for clarification.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Please ensure your answer is thorough and detailed, offering \n",
    "insights and explanations to support your conclusions.\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Either build a new datastore or use an existing one\n",
    "datastore = DocArrayInMemorySearch.from_documents(documents, embeddings)\n",
    "\n",
    "# Run the RAG model and print the output\n",
    "chain = (\n",
    "    {\"context\": datastore.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting output text...\n",
      "The transcript provided seems to be a lecture on matrix operations and linear algebra concepts. The\n",
      "professor starts by discussing elimination matrices and elementary matrices used in the process of\n",
      "transforming a matrix. The lecture then progresses to combining these steps into a single matrix that\n",
      "performs all the transformations. The professor emphasizes the importance of matrix notation in\n",
      "condensing complex operations into concise representations.\n",
      "\n",
      "The lecture also touches on matrix multiplication and the associative law, highlighting the\n",
      "significance of being able to rearrange parentheses in matrix operations. The professor explains the\n",
      "process of back substitution and how elimination can be expressed in matrix language. The lecture\n",
      "includes examples of solving systems of equations using matrices and the importance of understanding\n",
      "matrix operations in the context of linear algebra.\n",
      "\n",
      "Overall, the professor's objective seems to be to teach students about the fundamental concepts of\n",
      "matrix operations, elimination, and back substitution in the context of solving systems of equations.\n",
      "The lecture aims to demonstrate how these concepts can be expressed using matrices and how matrix\n",
      "notation simplifies complex mathematical operations. The professor encourages students to understand\n",
      "the underlying principles of matrix operations to effectively solve problems in linear algebra.\n"
     ]
    }
   ],
   "source": [
    "store_data = chain.invoke(\"Please give a detailed summary of the transcript. What were the pertinent subjects discussed? Were there any key points or moments of contention?\")\n",
    "\n",
    "# Format the text with n=100\n",
    "formatted_text = format_text(store_data, 100)\n",
    "\n",
    "# Print the formatted text\n",
    "print(formatted_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
